{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143203c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenized data...\n",
      "✓ Data loaded: 54,050 tokens\n",
      "✓ Vocabulary size: 34\n",
      "\n",
      "============================================================\n",
      "CREATING DATASET\n",
      "============================================================\n",
      "Sequence length: 64\n",
      "Total sequences: 53,986\n",
      "\n",
      "Train sequences: 48,587\n",
      "Val sequences: 5,399\n",
      "\n",
      "Batch size: 32\n",
      "Train batches: 1,519\n",
      "Val batches: 169\n",
      "\n",
      "============================================================\n",
      "EXAMINING ONE BATCH\n",
      "============================================================\n",
      "Input batch shape: torch.Size([32, 64])\n",
      "Target batch shape: torch.Size([32, 64])\n",
      "\n",
      "============================================================\n",
      "FIRST SEQUENCE IN BATCH\n",
      "============================================================\n",
      "Input text:\n",
      "' cat gently. The cat would purr loudly. Tom loved his cat very m'\n",
      "\n",
      "Target text (shifted by 1):\n",
      "'cat gently. The cat would purr loudly. Tom loved his cat very mu'\n",
      "\n",
      "============================================================\n",
      "TOKEN-BY-TOKEN VIEW (first 10 positions)\n",
      "============================================================\n",
      "Position | Input Char | Input ID | Target Char | Target ID\n",
      "------------------------------------------------------------\n",
      "       0 |            |        1 | c           |        14\n",
      "       1 | c          |       14 | a           |        12\n",
      "       2 | a          |       12 | t           |        29\n",
      "       3 | t          |       29 |             |         1\n",
      "       4 |            |        1 | g           |        18\n",
      "       5 | g          |       18 | e           |        16\n",
      "       6 | e          |       16 | n           |        24\n",
      "       7 | n          |       24 | t           |        29\n",
      "       8 | t          |       29 | l           |        22\n",
      "       9 | l          |       22 | y           |        33\n",
      "\n",
      "✓ Notice: Target is input shifted by 1 position\n",
      "  Model learns: given input, predict next character\n",
      "\n",
      "============================================================\n",
      "STEP 3 COMPLETE ✓\n",
      "============================================================\n",
      "✓ Dataset created\n",
      "✓ Split into train/val\n",
      "✓ DataLoaders ready\n",
      "✓ Ready to build model!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load tokenized data\n",
    "print(\"Loading tokenized data...\")\n",
    "checkpoint = torch.load('tokenized_data.pt')\n",
    "data = checkpoint['data']\n",
    "char_to_idx = checkpoint['char_to_idx']\n",
    "idx_to_char = checkpoint['idx_to_char']\n",
    "vocab_size = checkpoint['vocab_size']\n",
    "\n",
    "print(f\"✓ Data loaded: {len(data):,} tokens\")\n",
    "print(f\"✓ Vocabulary size: {vocab_size}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get sequence of seq_len + 1 tokens\n",
    "        chunk = self.data[idx:idx + self.seq_len + 1]\n",
    "        \n",
    "        # Input: first seq_len tokens\n",
    "        x = chunk[:-1]\n",
    "        \n",
    "        # Target: shifted by 1 (next character prediction)\n",
    "        y = chunk[1:]\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "# Create dataset\n",
    "seq_len = 64  # Context length\n",
    "dataset = CharDataset(data, seq_len)\n",
    "\n",
    "print(f\"Sequence length: {seq_len}\")\n",
    "print(f\"Total sequences: {len(dataset):,}\")\n",
    "\n",
    "# Split into train/val\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain sequences: {len(train_dataset):,}\")\n",
    "print(f\"Val sequences: {len(val_dataset):,}\")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nBatch size: {batch_size}\")\n",
    "print(f\"Train batches: {len(train_loader):,}\")\n",
    "print(f\"Val batches: {len(val_loader):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMINING ONE BATCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get one batch\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "print(f\"Input batch shape: {x_batch.shape}\")  # [batch_size, seq_len]\n",
    "print(f\"Target batch shape: {y_batch.shape}\")  # [batch_size, seq_len]\n",
    "\n",
    "# Show first sequence\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIRST SEQUENCE IN BATCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "x_sample = x_batch[0]\n",
    "y_sample = y_batch[0]\n",
    "\n",
    "# Decode to text\n",
    "x_text = ''.join([idx_to_char[i.item()] for i in x_sample])\n",
    "y_text = ''.join([idx_to_char[i.item()] for i in y_sample])\n",
    "\n",
    "print(\"Input text:\")\n",
    "print(f\"'{x_text}'\")\n",
    "print(\"\\nTarget text (shifted by 1):\")\n",
    "print(f\"'{y_text}'\")\n",
    "\n",
    "# Show token-by-token\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOKEN-BY-TOKEN VIEW (first 10 positions)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Position | Input Char | Input ID | Target Char | Target ID\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(10):\n",
    "    in_char = idx_to_char[x_sample[i].item()]\n",
    "    in_id = x_sample[i].item()\n",
    "    tgt_char = idx_to_char[y_sample[i].item()]\n",
    "    tgt_id = y_sample[i].item()\n",
    "    print(f\"{i:8d} | {in_char:10s} | {in_id:8d} | {tgt_char:11s} | {tgt_id:9d}\")\n",
    "\n",
    "print(\"\\n✓ Notice: Target is input shifted by 1 position\")\n",
    "print(\"  Model learns: given input, predict next character\")\n",
    "\n",
    "# Save for next step\n",
    "torch.save({\n",
    "    'train_loader': train_loader,\n",
    "    'val_loader': val_loader,\n",
    "    'vocab_size': vocab_size,\n",
    "    'idx_to_char': idx_to_char,\n",
    "    'char_to_idx': char_to_idx,\n",
    "    'seq_len': seq_len\n",
    "}, 'data_loaders.pt')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3 COMPLETE ✓\")\n",
    "print(\"=\"*60)\n",
    "print(\"✓ Dataset created\")\n",
    "print(\"✓ Split into train/val\")\n",
    "print(\"✓ DataLoaders ready\")\n",
    "print(\"✓ Ready to build model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c6800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718b5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9801a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1277e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f420b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
